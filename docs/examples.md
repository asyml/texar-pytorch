# Examples #

Rich examples are included to demonstrate the use of Texar. The implementations of cutting-edge models/algorithms also provide references for reproducibility and comparisons. 

More examples are continuously added...

## Examples by Models/Algorithms ##

### RNN / Seq2seq ###

* [seq2seq_attn](https://github.com/asyml/texar-pytorch/tree/master/examples/seq2seq_attn): Attentional seq2seq

### Transformer (Self-attention) ###

* [transformer](https://github.com/asyml/texar-pytorch/tree/master/examples/transformer): Transformer for machine translation
* [bert](https://github.com/asyml/texar-pytorch/tree/master/examples/bert): Pre-trained BERT model for text representation
* [gpt-2](https://github.com/asyml/texar-pytorch/tree/master/examples/gpt-2): Pre-trained OpenAI GPT-2 language model
* [xlnet](https://github.com/asyml/texar-pytorch/tree/master/examples/xlnet): Pre-trained XLNet model for text representation

### Classifier / Sequence Prediction ###  

* [bert](https://github.com/asyml/texar-pytorch/tree/master/examples/bert): Pre-trained BERT model for text representation
* [xlnet](https://github.com/asyml/texar-pytorch/tree/master/examples/xlnet): Pre-trained XLNet model for text representation

---

## Examples by Tasks

### Language Modeling ###

* [gpt-2](https://github.com/asyml/texar-pytorch/tree/master/examples/gpt-2): Pre-trained OpenAI GPT-2 language model

### Machine Translation ###

* [seq2seq_attn](https://github.com/asyml/texar-pytorch/tree/master/examples/seq2seq_attn): Attentional seq2seq
* [transformer](https://github.com/asyml/texar-pytorch/tree/master/examples/transformer): Transformer for machine translation

### Classification ###

* [bert](https://github.com/asyml/texar-pytorch/tree/master/examples/bert): Pre-trained BERT model for text representation
* [xlnet](https://github.com/asyml/texar-pytorch/tree/master/examples/xlnet): Pre-trained XLNet model for text representation
